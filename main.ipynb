{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "import onnxruntime\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from skimage import transform as trans\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "prev_time = None\n",
    "def timepoint(text):\n",
    "    global prev_time\n",
    "    if prev_time:\n",
    "        elapsed_time = time.time() - prev_time\n",
    "        print(f\"{text}: {int(elapsed_time*1000)}ms\")\n",
    "    prev_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_align\n",
    "arcface_dst = np.array(\n",
    "    [[38.2946, 51.6963], [73.5318, 51.5014], [56.0252, 71.7366],\n",
    "     [41.5493, 92.3655], [70.7299, 92.2041]],\n",
    "    dtype=np.float32)\n",
    "\n",
    "def estimate_norm(lmk, image_size=112, mode='arcface'):\n",
    "    assert lmk.shape == (5, 2)\n",
    "    assert image_size%112==0 or image_size%128==0\n",
    "    if image_size%112==0:\n",
    "        ratio = float(image_size)/112.0\n",
    "        diff_x = 0\n",
    "    else:\n",
    "        ratio = float(image_size)/128.0\n",
    "        diff_x = 8.0*ratio\n",
    "    dst = arcface_dst * ratio\n",
    "    dst[:,0] += diff_x\n",
    "    tform = trans.SimilarityTransform()\n",
    "    tform.estimate(lmk, dst)\n",
    "    M = tform.params[0:2, :]\n",
    "    return M\n",
    "\n",
    "def norm_crop2(img, landmark, image_size=112, mode='arcface'):\n",
    "    M = estimate_norm(landmark, image_size, mode)\n",
    "    warped = cv2.warpAffine(img, M, (image_size, image_size), borderValue=0.0)\n",
    "    return warped, M\n",
    "\n",
    "def norm_crop(img, landmark, image_size=112, mode='arcface'):\n",
    "    warped, _ = norm_crop2(img, landmark, image_size, mode)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.337291"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "class ArcFaceONNX:\n",
    "    def __init__(self):\n",
    "        self.session = onnxruntime.InferenceSession(\"buffalo_l/w600k_r50.onnx\", providers=['CPUExecutionProvider'])\n",
    "        self.input_mean = 127.5\n",
    "        self.input_std = 127.5\n",
    "        self.input_names = [input.name for input in self.session.get_inputs()]\n",
    "        self.output_names = [output.name for output in self.session.get_outputs()]\n",
    "\n",
    "        input_cfg = self.session.get_inputs()[0]\n",
    "        input_shape = input_cfg.shape\n",
    "        self.input_size = tuple(input_shape[2:4][::-1])\n",
    "        self.input_name = self.input_names[0]\n",
    "\n",
    "    def get_feat(self, imgs):\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        blob = cv2.dnn.blobFromImages(imgs, 1.0 / self.input_std, self.input_size,\n",
    "                                        (self.input_mean, self.input_mean, self.input_mean), swapRB=True)\n",
    "        return self.session.run(self.output_names, {self.input_name: blob})[0]    \n",
    "    \n",
    "    def get_embedding(self, img, face_kps):\n",
    "        aimg = norm_crop(img, landmark=face_kps, image_size=self.input_size[0])\n",
    "        return self.get_feat(aimg).flatten()\n",
    "\n",
    "def embedding_norm(embedding):\n",
    "    if embedding is None:\n",
    "        return None\n",
    "    return norm(embedding)\n",
    "\n",
    "def normed_embedding(embedding):\n",
    "    if embedding is None:\n",
    "        return None\n",
    "    return embedding / embedding_norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[202.74078, 244.44377],\n",
       "       [313.35687, 236.37285],\n",
       "       [268.4746 , 308.40735],\n",
       "       [210.28693, 345.5235 ],\n",
       "       [317.6929 , 337.33698]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance2kps(points, distance, max_shape=None):\n",
    "    \"\"\"Decode distance prediction to bounding box.\n",
    "\n",
    "    Args:\n",
    "        points (Tensor): Shape (n, 2), [x, y].\n",
    "        distance (Tensor): Distance from the given point to 4\n",
    "            boundaries (left, top, right, bottom).\n",
    "        max_shape (tuple): Shape of the image.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Decoded bboxes.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    for i in range(0, distance.shape[1], 2):\n",
    "        px = points[:, i%2] + distance[:, i]\n",
    "        py = points[:, i%2+1] + distance[:, i+1]\n",
    "        if max_shape is not None:\n",
    "            px = px.clamp(min=0, max=max_shape[1])\n",
    "            py = py.clamp(min=0, max=max_shape[0])\n",
    "        preds.append(px)\n",
    "        preds.append(py)\n",
    "    return np.stack(preds, axis=-1)\n",
    "\n",
    "def distance2bbox(points, distance, max_shape=None):\n",
    "    x1 = points[:, 0] - distance[:, 0]\n",
    "    y1 = points[:, 1] - distance[:, 1]\n",
    "    x2 = points[:, 0] + distance[:, 2]\n",
    "    y2 = points[:, 1] + distance[:, 3]\n",
    "    if max_shape is not None:\n",
    "        x1 = x1.clamp(min=0, max=max_shape[1])\n",
    "        y1 = y1.clamp(min=0, max=max_shape[0])\n",
    "        x2 = x2.clamp(min=0, max=max_shape[1])\n",
    "        y2 = y2.clamp(min=0, max=max_shape[0])\n",
    "    return np.stack([x1, y1, x2, y2], axis=-1)\n",
    "\n",
    "class RetinaFace:\n",
    "    def __init__(self):\n",
    "        self.session = onnxruntime.InferenceSession(\"buffalo_l/det_10g.onnx\", providers=['CPUExecutionProvider'])\n",
    "        self.input_mean = 127.5\n",
    "        self.input_std = 127.5\n",
    "        self.input_names = [input.name for input in self.session.get_inputs()]\n",
    "        self.output_names = [output.name for output in self.session.get_outputs()]\n",
    "        self.nms_thresh = 0.4\n",
    "        self.det_thresh = 0.5\n",
    "        self.input_name = self.input_names[0]\n",
    "        self.center_cache = {}\n",
    "\n",
    "        if len(self.output_names)==6:\n",
    "            self.fmc = 3\n",
    "            self._feat_stride_fpn = [8, 16, 32]\n",
    "            self._num_anchors = 2\n",
    "        elif len(self.output_names)==9:\n",
    "            self.fmc = 3\n",
    "            self._feat_stride_fpn = [8, 16, 32]\n",
    "            self._num_anchors = 2\n",
    "            self.use_kps = True\n",
    "        elif len(self.output_names)==10:\n",
    "            self.fmc = 5\n",
    "            self._feat_stride_fpn = [8, 16, 32, 64, 128]\n",
    "            self._num_anchors = 1\n",
    "        elif len(self.output_names)==15:\n",
    "            self.fmc = 5\n",
    "            self._feat_stride_fpn = [8, 16, 32, 64, 128]\n",
    "            self._num_anchors = 1\n",
    "            self.use_kps = True\n",
    "\n",
    "    def nms(self, dets):\n",
    "        thresh = self.nms_thresh\n",
    "        x1 = dets[:, 0]\n",
    "        y1 = dets[:, 1]\n",
    "        x2 = dets[:, 2]\n",
    "        y2 = dets[:, 3]\n",
    "        scores = dets[:, 4]\n",
    "\n",
    "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        order = scores.argsort()[::-1]\n",
    "\n",
    "        keep = []\n",
    "        while order.size > 0:\n",
    "            i = order[0]\n",
    "            keep.append(i)\n",
    "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "            inter = w * h\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "            inds = np.where(ovr <= thresh)[0]\n",
    "            order = order[inds + 1]\n",
    "\n",
    "        return keep\n",
    "    \n",
    "    def forward(self, img, threshold):\n",
    "        scores_list = []\n",
    "        bboxes_list = []\n",
    "        kpss_list = []\n",
    "        input_size = tuple(img.shape[0:2][::-1])\n",
    "        blob = cv2.dnn.blobFromImage(img, 1.0/self.input_std, input_size, (self.input_mean, self.input_mean, self.input_mean), swapRB=True)\n",
    "        net_outs = self.session.run(self.output_names, {self.input_name : blob})\n",
    "\n",
    "        input_height = blob.shape[2]\n",
    "        input_width = blob.shape[3]\n",
    "        fmc = self.fmc\n",
    "        for idx, stride in enumerate(self._feat_stride_fpn):\n",
    "            scores = net_outs[idx]\n",
    "            bbox_preds = net_outs[idx+fmc]\n",
    "            bbox_preds = bbox_preds * stride\n",
    "            kps_preds = net_outs[idx+fmc*2] * stride\n",
    "            height = input_height // stride\n",
    "            width = input_width // stride\n",
    "            K = height * width\n",
    "            key = (height, width, stride)\n",
    "            if key in self.center_cache:\n",
    "                anchor_centers = self.center_cache[key]\n",
    "            else:\n",
    "                anchor_centers = np.stack(np.mgrid[:height, :width][::-1], axis=-1).astype(np.float32)\n",
    "\n",
    "                anchor_centers = (anchor_centers * stride).reshape( (-1, 2) )\n",
    "                if self._num_anchors>1:\n",
    "                    anchor_centers = np.stack([anchor_centers]*self._num_anchors, axis=1).reshape( (-1,2) )\n",
    "                if len(self.center_cache)<100:\n",
    "                    self.center_cache[key] = anchor_centers\n",
    "\n",
    "            pos_inds = np.where(scores>=threshold)[0]\n",
    "            bboxes = distance2bbox(anchor_centers, bbox_preds)\n",
    "            pos_scores = scores[pos_inds]\n",
    "            pos_bboxes = bboxes[pos_inds]\n",
    "            scores_list.append(pos_scores)\n",
    "            bboxes_list.append(pos_bboxes)\n",
    "            if self.use_kps:\n",
    "                kpss = distance2kps(anchor_centers, kps_preds)\n",
    "                kpss = kpss.reshape( (kpss.shape[0], -1, 2) )\n",
    "                pos_kpss = kpss[pos_inds]\n",
    "                kpss_list.append(pos_kpss)\n",
    "        return scores_list, bboxes_list, kpss_list\n",
    "\n",
    "    def detect(self, img, input_size = None, max_num=0, metric='default'):\n",
    "        assert input_size is not None or self.input_size is not None\n",
    "        input_size = self.input_size if input_size is None else input_size\n",
    "\n",
    "        im_ratio = float(img.shape[0]) / img.shape[1]\n",
    "        model_ratio = float(input_size[1]) / input_size[0]\n",
    "        if im_ratio>model_ratio:\n",
    "            new_height = input_size[1]\n",
    "            new_width = int(new_height / im_ratio)\n",
    "        else:\n",
    "            new_width = input_size[0]\n",
    "            new_height = int(new_width * im_ratio)\n",
    "        det_scale = float(new_height) / img.shape[0]\n",
    "        resized_img = cv2.resize(img, (new_width, new_height))\n",
    "        det_img = np.zeros((input_size[1], input_size[0], 3), dtype=np.uint8)\n",
    "        det_img[:new_height, :new_width, :] = resized_img\n",
    "\n",
    "        scores_list, bboxes_list, kpss_list = self.forward(det_img, self.det_thresh)\n",
    "\n",
    "        scores = np.vstack(scores_list)\n",
    "        scores_ravel = scores.ravel()\n",
    "        order = scores_ravel.argsort()[::-1]\n",
    "        bboxes = np.vstack(bboxes_list) / det_scale\n",
    "        kpss = np.vstack(kpss_list) / det_scale\n",
    "        pre_det = np.hstack((bboxes, scores)).astype(np.float32, copy=False)\n",
    "        pre_det = pre_det[order, :]\n",
    "        keep = self.nms(pre_det)\n",
    "        det = pre_det[keep, :]\n",
    "\n",
    "        kpss = kpss[order,:,:]\n",
    "        kpss = kpss[keep,:,:]\n",
    "\n",
    "        if max_num > 0 and det.shape[0] > max_num:\n",
    "            area = (det[:, 2] - det[:, 0]) * (det[:, 3] -\n",
    "                                                    det[:, 1])\n",
    "            img_center = img.shape[0] // 2, img.shape[1] // 2\n",
    "\n",
    "            offsets = np.vstack([\n",
    "                (det[:, 0] + det[:, 2]) / 2 - img_center[1],\n",
    "                (det[:, 1] + det[:, 3]) / 2 - img_center[0]\n",
    "            ])\n",
    "            offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n",
    "\n",
    "            if metric == 'max':\n",
    "                values = area\n",
    "            else:\n",
    "                values = area - offset_dist_squared * 2.0  # some extra weight on the centering\n",
    "            bindex = np.argsort(values)[::-1]  # some extra weight on the centering\n",
    "            bindex = bindex[0:max_num]\n",
    "            kpss = kpss[bindex, :]\n",
    "        return kpss\n",
    "\n",
    "retinaface = RetinaFace()\n",
    "print(len(retinaface.session.get_outputs()))\n",
    "kpss = retinaface.detect(cv2.imread(\"suzu.jpg\"), input_size=(640, 640))\n",
    "kpss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import numpy_helper\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import cv2\n",
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "class INSwapper:\n",
    "    def __init__(self):\n",
    "        model_file = 'models/inswapper_128.onnx'\n",
    "        model = onnx.load(model_file)\n",
    "        self.emap = numpy_helper.to_array(model.graph.initializer[-1])\n",
    "        self.session = onnxruntime.InferenceSession(model_file, providers=['CPUExecutionProvider'])\n",
    "\n",
    "        self.input_mean = 0.0\n",
    "        self.input_std = 255.0\n",
    "        self.input_names = [input.name for input in self.session.get_inputs()]\n",
    "        self.output_names = [output.name for output in self.session.get_outputs()]\n",
    "\n",
    "        self.output_shape = self.session.get_outputs()[0].shape\n",
    "        self.input_shape = self.session.get_inputs()[0].shape\n",
    "        self.input_size = tuple(self.input_shape[2:4][::-1])\n",
    "\n",
    "    def swap(self, img, source_face_normed_embedding, target_face_kps):\n",
    "\n",
    "        timepoint(\"start\")\n",
    "        aimg, M = norm_crop2(img, target_face_kps, self.input_size[0])\n",
    "        blob = cv2.dnn.blobFromImage(aimg, 1.0 / self.input_std, self.input_size,\n",
    "                                    (self.input_mean, self.input_mean, self.input_mean), swapRB=True)\n",
    "\n",
    "        timepoint(\"norm_crop2\")\n",
    "\n",
    "        latent = source_face_normed_embedding.reshape((1,-1))\n",
    "        latent = np.dot(latent, self.emap)\n",
    "        latent /= np.linalg.norm(latent)\n",
    "        timepoint(\"latent\")\n",
    "\n",
    "        pred = self.session.run(self.output_names, {self.input_names[0]: blob, self.input_names[1]: latent})[0]\n",
    "        timepoint(\"session.run\")\n",
    "\n",
    "        #print(latent.shape, latent.dtype, pred.shape)\n",
    "        img_fake = pred.transpose((0,2,3,1))[0]\n",
    "        bgr_fake = np.clip(255 * img_fake, 0, 255).astype(np.uint8)[:,:,::-1]\n",
    "        timepoint(\"clip\")\n",
    "\n",
    "        target_img = img\n",
    "        fake_diff = bgr_fake.astype(np.float32) - aimg.astype(np.float32)\n",
    "        fake_diff = np.abs(fake_diff).mean(axis=2)\n",
    "        timepoint(\"np.abs\")\n",
    "\n",
    "        fake_diff[:2,:] = 0\n",
    "        fake_diff[-2:,:] = 0\n",
    "        fake_diff[:,:2] = 0\n",
    "        fake_diff[:,-2:] = 0\n",
    "        IM = cv2.invertAffineTransform(M)\n",
    "        timepoint(\"invertAffineTransform\")\n",
    "\n",
    "        img_white = np.full((aimg.shape[0],aimg.shape[1]), 255, dtype=np.float32)\n",
    "        bgr_fake = cv2.warpAffine(bgr_fake, IM, (target_img.shape[1], target_img.shape[0]), borderValue=0.0)\n",
    "        img_white = cv2.warpAffine(img_white, IM, (target_img.shape[1], target_img.shape[0]), borderValue=0.0)\n",
    "        fake_diff = cv2.warpAffine(fake_diff, IM, (target_img.shape[1], target_img.shape[0]), borderValue=0.0)\n",
    "        timepoint(\"warpAffine\")\n",
    "\n",
    "        img_white[img_white>20] = 255\n",
    "        fthresh = 10\n",
    "        fake_diff[fake_diff<fthresh] = 0\n",
    "        fake_diff[fake_diff>=fthresh] = 255\n",
    "        img_mask = img_white\n",
    "        mask_h_inds, mask_w_inds = np.where(img_mask==255)\n",
    "        mask_h = np.max(mask_h_inds) - np.min(mask_h_inds)\n",
    "        mask_w = np.max(mask_w_inds) - np.min(mask_w_inds)\n",
    "        mask_size = int(np.sqrt(mask_h*mask_w))\n",
    "        k = max(mask_size//10, 10)\n",
    "        #k = max(mask_size//20, 6)\n",
    "        #k = 6\n",
    "        timepoint(\"maxmax\")\n",
    "\n",
    "        kernel = np.ones((k,k),np.uint8)\n",
    "        img_mask = cv2.erode(img_mask, kernel, iterations = 1)\n",
    "        kernel = np.ones((2,2),np.uint8)\n",
    "        fake_diff = cv2.dilate(fake_diff, kernel, iterations = 1)\n",
    "        k = max(mask_size//20, 5)\n",
    "        timepoint(\"cv2\")\n",
    "        #k = 3\n",
    "        #k = 3\n",
    "        kernel_size = (k, k)\n",
    "        blur_size = tuple(2*i+1 for i in kernel_size)\n",
    "        img_mask = cv2.GaussianBlur(img_mask, blur_size, 0)\n",
    "        k = 5\n",
    "        kernel_size = (k, k)\n",
    "        blur_size = tuple(2*i+1 for i in kernel_size)\n",
    "        fake_diff = cv2.GaussianBlur(fake_diff, blur_size, 0)\n",
    "        img_mask /= 255\n",
    "        fake_diff /= 255\n",
    "        #img_mask = fake_diff\n",
    "\n",
    "        timepoint(\"GaussianBlur\")\n",
    "\n",
    "        img_mask = np.reshape(img_mask, [img_mask.shape[0],img_mask.shape[1],1])\n",
    "        fake_merged = img_mask * bgr_fake + (1-img_mask) * target_img.astype(np.float32)\n",
    "        fake_merged = fake_merged.astype(np.uint8)\n",
    "        cv2.imwrite(\"result.jpg\", fake_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 13:13:49.747330 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'buff2fs'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "source_img = cv2.imread(\"suzu.jpg\")\n",
    "target_img = cv2.imread(\"org.jpg\")\n",
    "retinaface = RetinaFace()\n",
    "arcface = ArcFaceONNX()\n",
    "swapper = INSwapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_analyzer = insightface.app.FaceAnalysis(name='buffalo_l')\n",
    "face_analyzer.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "source_face = face_analyzer.get(source_img)\n",
    "target_face = face_analyzer.get(target_img)\n",
    "\n",
    "swapper.swap(target_img, target_normed_embedding, target_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 174073ms\n",
      "norm_crop2: 0ms\n",
      "latent: 4ms\n",
      "session.run: 1065ms\n",
      "clip: 0ms\n",
      "np.abs: 0ms\n",
      "invertAffineTransform: 0ms\n",
      "warpAffine: 1ms\n",
      "maxmax: 1ms\n",
      "cv2: 0ms\n",
      "GaussianBlur: 1ms\n"
     ]
    }
   ],
   "source": [
    "source_kps = retinaface.detect(source_img, input_size=(640, 640))[0]\n",
    "target_kps = retinaface.detect(target_img, input_size=(640, 640))[0]\n",
    "\n",
    "source_embedding = arcface.get_embedding(source_img, source_kps)\n",
    "source_normed_embedding = normed_embedding(source_embedding)\n",
    "\n",
    "swapper.swap(target_img, source_normed_embedding, target_kps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
